#!/usr/bin/python
from __future__ import division
import re
import nltk
import sys
import getopt
import math


def build_LM(in_file):
    """
    build language models for each label
    each line in in_file contains a label and an URL separated by a tab(\t)
    """
    print 'building language models...'
    # This is an empty method
    # Pls implement your code in below

    # Open in_file and split into a list of sentences
    input_file = open(in_file, 'r')
    train_input_list = input_file.read().split("\r\n")

    # Set up dictionaries to store the 4grams generated from input.train
    # ngram_count stores the total number of ngrams each language has generated
    four_gram_table = {}
    ngram_count = {'malaysian': 0, 'indonesian': 0, 'tamil': 0}

    '''
    NGRAM GENERATION
    Multiple for loops through each sentence and then each character for
    4gram generation. Each sentence is padded with 3 'START's and 3 'END's
    '''
    for sentence in train_input_list:
        sentence_parts = sentence.split(None, 1)
        # To handle possible empty strings or weird strings in training input
        if (len(sentence_parts) != 2):
            break
        language = sentence_parts[0]
        sentence_body = sentence_parts[1]
        char_list = list(sentence_body)
        for index in range(3):
            char_list.insert(0, 'START')
            char_list.append('END')
        for index in range(len(char_list) - 4):
            four_gram = (char_list[index], char_list[index + 1],
                         char_list[index + 2], char_list[index + 3])
            if four_gram in four_gram_table:
                four_gram_table[four_gram][language] += 1
                ngram_count[language] += 1
            else:
                # Add-one smoothing for new ngrams
                four_gram_table[four_gram] = {'malaysian': 1, 'indonesian': 1,
                                              'tamil': 1}
                for value in ngram_count.itervalues():
                    value += 1
                four_gram_table[four_gram][language] += 1
                ngram_count[language] += 1
    return [four_gram_table, ngram_count]

    input_file.close()


def test_LM(in_file, out_file, LM):
    """
    test the language models on new URLs
    each line of in_file contains an URL
    you should print the most probable label for each URL into out_file
    """
    print "testing language models..."
    # This is an empty method
    # Pls implement your code in below

    # Setting up data provided from given LM
    four_gram_table = LM[0]
    ngram_count = LM[1]

    # Open in_file and split into a list of sentences
    # Open out_file for writing predictions
    input_file = open(in_file, 'r')
    test_input_list = input_file.read().split("\r\n")
    output_file = open(out_file, 'w')

    for sentence in test_input_list:
        # To handle possible empty strings or invalid input
        if sentence == "":
            break
        # Ngram probability score for current sentence
        ngram_score = {'malaysian': 0, 'indonesian': 0, 'tamil': 0}
        # Counters to keep track of number of unencountered ngrams generated by
        # the current sentence.
        invalid_ngram_count = 0
        total_ngram_count = 0
        # Sentence is padded with 3 'START's and 3 'END's
        char_list = list(sentence)
        for index in range(3):
            char_list.insert(0, 'START')
            char_list.append('END')
        for index in range(len(char_list) - 4):
            four_gram = (char_list[index], char_list[index + 1],
                         char_list[index + 2], char_list[index + 3])
            # Log10 is used to prevent underflow of individual ngram_scores
            if four_gram in four_gram_table:
                for language, count in four_gram_table[four_gram].iteritems():
                    ngram_score[language] += math.log10(count/ngram_count[language])
            else:
                invalid_ngram_count += 1
            total_ngram_count += 1
        # invalid_ngram_ratio represents the proportion of unencountered ngrams
        # out of all ngrams generated from current sentence
        invalid_ngram_ratio = invalid_ngram_count / total_ngram_count
        # The set threshold of 0.6 indicates that the sentence might not be a
        # valid language in the given LM
        if max(ngram_score.itervalues()) is 0 or invalid_ngram_ratio > 0.6:
            predicted_language = 'other'
        else:
            predicted_language = max(ngram_score.iterkeys(), key=(lambda language: ngram_score[language]))
        output_file.write(predicted_language + " " + sentence + "\n")
    input_file.close
    output_file.close


def usage():
    print "usage: " + sys.argv[0] + " -b input-file-for-building-LM -t input-file-for-testing-LM -o output-file"

input_file_b = input_file_t = output_file = None
try:
    opts, args = getopt.getopt(sys.argv[1:], 'b:t:o:')
except getopt.GetoptError, err:
    usage()
    sys.exit(2)
for o, a in opts:
    if o == '-b':
        input_file_b = a
    elif o == '-t':
        input_file_t = a
    elif o == '-o':
        output_file = a
    else:
        assert False, "unhandled option"
if input_file_b == None or input_file_t == None or output_file == None:
    usage()
    sys.exit(2)

LM = build_LM(input_file_b)
test_LM(input_file_t, output_file, LM)
